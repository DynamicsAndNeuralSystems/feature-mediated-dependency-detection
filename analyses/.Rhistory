install.packages("rJava")
library("rJava")
.jinit()
# Change location of jar to match yours:
#  IMPORTANT -- If using the default below, make sure you have set the working directory
#   in R (e.g. with setwd()) to the location of this file (i.e. demos/r) !!
.jaddClassPath("/Users/arianguyen/featureBasedMeasurements_R/infodynamics.jar")
sourceArray<-sample(0:1, 100, replace=TRUE)
destArray<-c(0L, sourceArray[1:99]); # Need 0L to keep as integer array
sourceArray2<-sample(0:1, 100, replace=TRUE)
# Create a TE calculator and run it:
teCalc<-.jnew("infodynamics/measures/discrete/TransferEntropyCalculatorDiscrete", 2L, 1L)
.jcall(teCalc,"V","initialise") # V for void return value
.jcall(teCalc,"V","addObservations",sourceArray, destArray)
result1 <- .jcall(teCalc,"D","computeAverageLocalOfObservations")
cat("For copied source, result should be close to 1 bit : ", result1, "\n")
# Now look at the unrelated source:
.jcall(teCalc,"V","initialise") # V for void return value
.jcall(teCalc,"V","addObservations",sourceArray2, destArray)
result2 <- .jcall(teCalc,"D","computeAverageLocalOfObservations")
cat("For random source, result should be close to 0 bits: ", result2, "\n")
source <- c()
step_size <- 0.0005
freq_coefs_all <- c()
integrated_freqs <- c()
for (i in 1:BVF_number_segment){
if (i%%2 == 1){
freq_coefs <- seq(0.01,0.01+step_size*(segment_len-1),step_size)
} else {
freq_coefs <- seq(0.01+step_size*(segment_len-1),0.01,-1*step_size)
}
freq_coefs_all <- c(freq_coefs_all,freq_coefs)
if (i==1){
integrated_freqs[i] <- 0
} else {
integrated_freqs[i] <- integrated_freqs[i-1]+ (freq_coefs[i]+freq_coefs[i-1])/2
}
}
plot(freq_coefs_all,type="l",col="blue")
# Ben_varying_frequency
BVF_number_segment <- 20
# Generative processes
#ts_length <- 500
ts_length <- 5000
source <- c()
segment_len <- ts_length/BVF_number_segment
step_size <- 0.0005
freq_coefs_all <- c()
integrated_freqs <- c()
for (i in 1:BVF_number_segment){
if (i%%2 == 1){
freq_coefs <- seq(0.01,0.01+step_size*(segment_len-1),step_size)
} else {
freq_coefs <- seq(0.01+step_size*(segment_len-1),0.01,-1*step_size)
}
freq_coefs_all <- c(freq_coefs_all,freq_coefs)
if (i==1){
integrated_freqs[i] <- 0
} else {
integrated_freqs[i] <- integrated_freqs[i-1]+ (freq_coefs[i]+freq_coefs[i-1])/2
}
}
plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
BVF_number_segment
BVF_number_segment <- 5
ts_length <- 5000
BVF_number_segment <- 5
wave_step_size <- 1
source <- c()
segment_len <- ts_length/BVF_number_segment
step_size <- 0.0005
freq_coefs_all <- c()
integrated_freqs <- c()
for (i in 1:BVF_number_segment){
if (i%%2 == 1){
freq_coefs <- seq(0.01,0.01+step_size*(segment_len-1),step_size)
} else {
freq_coefs <- seq(0.01+step_size*(segment_len-1),0.01,-1*step_size)
}
freq_coefs_all <- c(freq_coefs_all,freq_coefs)
if (i==1){
integrated_freqs[i] <- 0
} else {
integrated_freqs[i] <- integrated_freqs[i-1]+ (freq_coefs[i]+freq_coefs[i-1])/2
}
}
plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
noise_coef <- 0
for (i in 1:BVF_number_segment){
if (i%%2 == 1){
freq_coefs <- seq(0.01,0.01+step_size*(segment_len-1),step_size)
} else {
freq_coefs <- seq(0.01+step_size*(segment_len-1),0.01,-1*step_size)
}
freq_coefs_all <- c(freq_coefs_all,freq_coefs)
if (i==1){
integrated_freqs[i] <- 0
} else {
integrated_freqs[i] <- integrated_freqs[i-1]+ (freq_coefs[i]+freq_coefs[i-1])/2
}
}
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
x <- seq(0,(segment_len-1)*wave_step_size,wave_step_size)
length(integrated_freqs)
length(x)
freq_coefs_all <- c()
integrated_freqs <- c()
for (i in 1:BVF_number_segment){
if (i%%2 == 1){
freq_coefs <- seq(0.01,0.01+step_size*(segment_len-1),step_size)
} else {
freq_coefs <- seq(0.01+step_size*(segment_len-1),0.01,-1*step_size)
}
freq_coefs_all <- c(freq_coefs_all,freq_coefs)
for (j in seq(1,segment_len,1)){
if (j==1){
integrated_freqs[j] <- 0
} else {
integrated_freqs[j] <- integrated_freqs[j-1]+ (freq_coefs[j]+freq_coefs[j-1])/2
}
}
}
#plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
x <- seq(0,(segment_len-1)*wave_step_size,wave_step_size)
length(x)
length(integrated_freqs)
x <- seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs
#plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
cos(1)
cos(x)
cos(2*pi*x)
#plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len) + offset
y <- x + integrated_freqs
y <- seq(0,(segment_len-1)*wave_step_size,wave_step_size) + integrated_freqs
cos(2*pi*y)
x <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))
length(x)
segment_len
offset
#plot(freq_coefs_all,type="l",col="blue")
segment <- cos(2*pi*(seq(0,(segment_len-1)*wave_step_size,wave_step_size)+integrated_freqs))+ noise_coef*rnorm(segment_len)
source <- c(source, segment)
plot(source, type="l",col="blue")
feature_window
J("java.lang.Runtime")$getRuntime()$gc()
setwd("/Users/arianguyen/Development/feature-mediated-dependency-detection")
packages <- readLines("requirements.txt")
# install required packages if they are not installed
for (p in packages) {
if (!requireNamespace(p, quietly = TRUE)) {
install.packages(p,repos = "http://cran.us.r-project.org")
}
}
source("setup.R")
source("src.R")
setwd("/Users/arianguyen/Development/feature-mediated-dependency-detection/analyses")
# function
process_results_summary <- function(data, summary_type,ts_length_filter, driving_feature_timescale_filter, capturing_feature_timescale_filter, linear_cor_filter) {
if (summary_type == "noise"){
filtered_data <- data %>%
filter(ts_length == ts_length_filter, driving_feature_timescale == driving_feature_timescale_filter, capturing_feature_timescale == capturing_feature_timescale_filter)
result_summary <- filtered_data %>%
group_by(process, ts_length, driving_feature, capturing_feature, noise_coef) %>%
summarise(avg_capture_rate_holm = mean(significant_pValue_holm) * 100) %>%
data.frame()
fipi_results <- filtered_data %>%
filter(!capturing_feature %in% c("null","signal","spike_count","autocorrelation_lag1","dominant_frequency")) %>%
group_by(process, ts_length, driving_feature, noise_coef, seed) %>%
summarise(fipi_detected = max(significant_pValue_holm)) %>%
group_by(process, ts_length, driving_feature, noise_coef) %>%
summarise(avg_capture_rate_holm = mean(fipi_detected) * 100) %>%
mutate(capturing_feature = "FIPI")
result_summary <- rbind.data.frame(fipi_results, result_summary)
return(result_summary)
}
if (summary_type == "driving_timescale"){
filtered_data <- data %>%
filter(ts_length == ts_length_filter, linear_cor == linear_cor_filter, capturing_feature_timescale == driving_feature_timescale)
result_summary <- filtered_data %>%
group_by(process, ts_length, driving_feature, capturing_feature, driving_feature_timescale) %>%
summarise(avg_capture_rate_holm = mean(significant_pValue_holm) * 100) %>%
data.frame()
fipi_results <- filtered_data %>%
filter(!capturing_feature %in% c("null","signal","spike_count","autocorrelation_lag1","dominant_frequency")) %>%
group_by(process, ts_length, driving_feature, driving_feature_timescale, seed) %>%
summarise(fipi_detected = max(significant_pValue_holm)) %>%
group_by(process, ts_length, driving_feature, driving_feature_timescale) %>%
summarise(avg_capture_rate_holm = mean(fipi_detected) * 100) %>%
mutate(capturing_feature = "FIPI")
result_summary <- rbind.data.frame(fipi_results, result_summary)
return(result_summary)
}
if (summary_type == "capturing_timescale"){
filtered_data <- data %>%
filter(ts_length == ts_length_filter, linear_cor == linear_cor_filter, driving_feature_timescale == driving_feature_timescale_filter)
result_summary <- filtered_data %>%
group_by(process, ts_length, driving_feature, capturing_feature, capturing_feature_timescale) %>%
summarise(avg_capture_rate_holm = mean(significant_pValue_holm) * 100) %>%
data.frame()
fipi_results <- filtered_data %>%
filter(!capturing_feature %in% c("null","signal","spike_count","autocorrelation_lag1","dominant_frequency")) %>%
group_by(process, ts_length, driving_feature, capturing_feature_timescale, seed) %>%
summarise(fipi_detected = max(significant_pValue_holm)) %>%
group_by(process, ts_length, driving_feature, capturing_feature_timescale) %>%
summarise(avg_capture_rate_holm = mean(fipi_detected) * 100) %>%
mutate(capturing_feature = "FIPI")
result_summary <- rbind.data.frame(fipi_results, result_summary)
return(result_summary)
}
}
## Read data
feature_name_mapping <- read.csv("../Feature_name_mapping.csv",header=T)
color_map <- c("null" = "#808080", "signal" = "black",
"mean"="#56B4E9","std"="#0B5394",
"mode_5"="#D55E00","mode_10"="#9e4600",
"trev"="#58D6A7",
"acf_timescale"="#E69F00","periodicity"="#a2a848","centroid_freq"="#FFAA00",
"autocorrelation_lag1"="#DC97BD","spike_count"="#CC79A7","dominant_frequency"="#E261A9",
"FIPI"="#008a7d")
# process all results
simulation_results <- read.csv(paste0(here("results","simulation_studies"),"/featureBasedDependency_simulation_results.csv"),header=T)
simulation_results <- unique(simulation_results)
# process all results
simulation_results <- read.csv(paste0(here("results","simulation_studies"),"/featureBasedDependency_simulation_results.csv"),header=T)
nrow(simulation_results)
simulation_results <- unique(simulation_results)
nrow(simulation_results)
simulation_results$seed <- as.integer(simulation_results$seed)
simulation_results$ts_length <- as.integer(simulation_results$ts_length)
simulation_results$driving_feature_timescale <- as.integer(simulation_results$driving_feature_timescale)
simulation_results$capturing_feature_timescale <- as.integer(simulation_results$capturing_feature_timescale)
simulation_results$linear_cor <- as.numeric(simulation_results$linear_cor)
simulation_results$TE <- as.numeric(simulation_results$TE)
simulation_results$pValue <- as.numeric(simulation_results$pValue)
simulation_results$driving_feature <- ifelse(simulation_results$driving_feature %in% feature_name_mapping$Feature,
feature_name_mapping$Short_name[match(simulation_results$driving_feature, feature_name_mapping$Feature)],
simulation_results$driving_feature)
simulation_results$capturing_feature <- ifelse(simulation_results$capturing_feature %in% feature_name_mapping$Feature,
feature_name_mapping$Short_name[match(simulation_results$capturing_feature, feature_name_mapping$Feature)],
simulation_results$capturing_feature)
simulation_results <- simulation_results %>%
group_by(seed, process, ts_length, driving_feature, driving_feature_timescale,linear_cor) %>%
mutate(
pValue_holm_corrected = ifelse(
inference_type == "ifpi",
p.adjust(pValue, method = "holm"),
pValue
)
)
simulation_results$significant_pValue_holm <- ifelse(simulation_results$pValue_holm_corrected<0.05,1,0)
head(simulation_results)
################### Random noise process result #####################
#####################################################################
random_results <- simulation_results[simulation_results$process=="random",]
nrow(random_results)
feature_values <- data.frame(matrix(ncol=24))
names(feature_values) <- unique(catch22_all(rnorm(10),catch24=T)$names)
for (seed in 1:50){
set.seed(seed)
ts <- rnorm(1000)
new_ts_feature_values <- catch22_all(ts,catch24 = T)
new_ts_feature_values <- pivot_wider(new_ts_feature_values,names_from = names, values_from = values)
feature_values <- rbind.data.frame(feature_values,new_ts_feature_values)
}
feature_values <- feature_values[-1,]
feature_correlation_matrix <- cor(feature_values,method="spearman")
# Perform hierarchical clustering on the feature correlation matrix
feature_cluster <- hclust(as.dist(1 - abs(feature_correlation_matrix)))
dendrogram <- as.dendrogram(feature_cluster)
plot(dendrogram, main = "Feature Clustering Dendrogram", xlab = "Features")
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 5)  # You can adjust the number of clusters (k) as needed
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
feature_values <- data.frame(matrix(ncol=24))
names(feature_values) <- unique(catch22_all(rnorm(10),catch24=T)$names)
for (seed in 1:50){
set.seed(seed)
ts <- rnorm(1000)
new_ts_feature_values <- catch22_all(ts,catch24 = T)
new_ts_feature_values <- pivot_wider(new_ts_feature_values,names_from = names, values_from = values)
feature_values <- rbind.data.frame(feature_values,new_ts_feature_values)
}
feature_values <- feature_values[-1,]
feature_correlation_matrix <- cor(feature_values,method="spearman")
# Perform hierarchical clustering on the feature correlation matrix
feature_cluster <- hclust(as.dist(1 - abs(feature_correlation_matrix)))
dendrogram <- as.dendrogram(feature_cluster)
plot(dendrogram, main = "Feature Clustering Dendrogram", xlab = "Features")
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 5)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
cluster_ids <- cutree(feature_cluster, k = 4)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 3)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
dendrogram <- as.dendrogram(feature_cluster)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
cluster_ids <- cutree(feature_cluster, k = 3)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
dendrogram <- as.dendrogram(feature_cluster)
plot(dendrogram, main = "Feature Clustering Dendrogram", xlab = "Features")
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 5)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
feature_values <- data.frame(matrix(ncol=24))
names(feature_values) <- unique(catch22_all(rnorm(10),catch24=T)$names)
for (seed in 1:50){
set.seed(seed)
ts <- rnorm(1000)
new_ts_feature_values <- catch22_all(ts,catch24 = T)
new_ts_feature_values <- pivot_wider(new_ts_feature_values,names_from = names, values_from = values)
feature_values <- rbind.data.frame(feature_values,new_ts_feature_values)
}
feature_values <- feature_values[-1,]
feature_correlation_matrix <- cor(feature_values,method="spearman")
# Perform hierarchical clustering on the feature correlation matrix
feature_cluster <- hclust(as.dist(1 - abs(feature_correlation_matrix)))
dendrogram <- as.dendrogram(feature_cluster)
plot(dendrogram, main = "Feature Clustering Dendrogram", xlab = "Features")
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 5)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
feature_cluster <- hclust(as.dist(1 - abs(feature_correlation_matrix)))
dendrogram <- as.dendrogram(feature_cluster)
plot(dendrogram, main = "Feature Clustering Dendrogram", xlab = "Features")
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 6)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
dendrogram_order <- order.dendrogram(as.dendrogram(feature_cluster))
# Order the features based on dendrogram order
ordered_feature_names <- names(feature_values)[dendrogram_order]
ordered_feature_names
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
ordered_feature_names
cluster_ids <- cutree(feature_cluster, k = 5)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
# Get the IDs for each cluster
cluster_ids <- cutree(feature_cluster, k = 5)
# Order the features based on cluster IDs
ordered_feature_names <- names(feature_values)[order(cluster_ids)]
ordered_feature_names
random_results_matrix <- random_results %>%
filter(capturing_feature != "null" & ts_length==1000) %>%
group_by(driving_feature, capturing_feature) %>%
summarise(avg_capture_rate=mean(significant_pValue_holm)*100)
# Order features by feature similarity (measured by the correlation of feature values across time series for each pair of features)
file_path <- paste0(here("ordered_feature_names.txt")) # this file is the result of running "order_features_by_similarity.R"
file_path
# Read the feature names from the text file
ordered_feature_names <- read.table(file = file_path, header = FALSE, sep = "\t", stringsAsFactors = FALSE)
feature_name_order <- ordered_feature_names$V1 # Extract the feature names as a character vector
feature_name_order
short_feature_order <- feature_name_mapping$Short_name[match(feature_name_order, feature_name_mapping$Feature)]
short_feature_order
features_to_remove <- c("SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1","SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1",
"SP_Summaries_welch_rect_area_5_1","SB_MotifThree_quantile_hh",
"IN_AutoMutualInfoStats_40_gaussian_fmmi","PD_PeriodicityWang_th0_01")
random_results_matrix <-  random_results_matrix[!random_results_matrix$capturing_feature%in%c(features_to_remove,"signal")
& !random_results_matrix$driving_feature%in%features_to_remove,]
random_results_matrix$driving_feature <- ifelse(random_results_matrix$driving_feature %in% feature_name_mapping$Feature,
feature_name_mapping$Short_name[match(random_results_matrix$driving_feature, feature_name_mapping$Feature)],
random_results_matrix$driving_feature)
random_results_matrix$capturing_feature <- ifelse(random_results_matrix$capturing_feature %in% feature_name_mapping$Feature,
feature_name_mapping$Short_name[match(random_results_matrix$capturing_feature, feature_name_mapping$Feature)],
random_results_matrix$capturing_feature)
random_results_matrix$driving_feature <- factor(random_results_matrix$driving_feature, levels = short_feature_order)
pdf("/Users/arianguyen/Library/CloudStorage/GoogleDrive-aria.mt.nguyen@gmail.com/My Drive/Master research /Feature based paper/Figures/RandomResultsMatrix2.pdf")
ggplot(random_results_matrix,aes(x = driving_feature, y = capturing_feature)) +
#make heatmap with geom_tile
geom_tile(aes(fill = avg_capture_rate)) +
#add the total number of devices to each tile
geom_fit_text(aes(label = round(avg_capture_rate)), size = 8) +
theme(axis.text.x=element_text(angle=90,hjust=1)) +
theme(text = element_text(size = 12))  +
#some formatting to make things easier to read
scale_x_discrete(position = "top") +
scale_fill_gradient(high = "#009688", low = "#DDF1EF") +
theme(legend.position = "none",
panel.grid = element_blank(),
panel.background = element_rect(fill = "white"),
axis.ticks = element_blank()) +
labs(x="Driving feature", y = "Capturing feature")
ggplot(random_results_matrix,aes(x = driving_feature, y = capturing_feature)) +
#make heatmap with geom_tile
geom_tile(aes(fill = avg_capture_rate)) +
#add the total number of devices to each tile
geom_fit_text(aes(label = round(avg_capture_rate)), size = 8) +
theme(axis.text.x=element_text(angle=90,hjust=1)) +
theme(text = element_text(size = 12))  +
#some formatting to make things easier to read
scale_x_discrete(position = "top") +
scale_fill_gradient(high = "#009688", low = "#DDF1EF") +
theme(legend.position = "none",
panel.grid = element_blank(),
panel.background = element_rect(fill = "white"),
axis.ticks = element_blank()) +
labs(x="Driving feature", y = "Capturing feature")
ggplot(random_results_matrix,aes(x = driving_feature, y = capturing_feature)) +
#make heatmap with geom_tile
geom_tile(aes(fill = avg_capture_rate)) +
#add the total number of devices to each tile
geom_fit_text(aes(label = round(avg_capture_rate)), size = 8) +
theme(axis.text.x=element_text(angle=90,hjust=1)) +
theme(text = element_text(size = 12))  +
#some formatting to make things easier to read
scale_x_discrete(position = "top") +
scale_fill_gradient(high = "#009688", low = "#DDF1EF") +
theme(legend.position = "none",
panel.grid = element_blank(),
panel.background = element_rect(fill = "white"),
axis.ticks = element_blank()) +
labs(x="Driving feature", y = "Capturing feature")
library(ggplot2)
ggplot(random_results_matrix,aes(x = driving_feature, y = capturing_feature)) +
#make heatmap with geom_tile
geom_tile(aes(fill = avg_capture_rate)) +
#add the total number of devices to each tile
geom_fit_text(aes(label = round(avg_capture_rate)), size = 8) +
theme(axis.text.x=element_text(angle=90,hjust=1)) +
theme(text = element_text(size = 12))  +
#some formatting to make things easier to read
scale_x_discrete(position = "top") +
scale_fill_gradient(high = "#009688", low = "#DDF1EF") +
theme(legend.position = "none",
panel.grid = element_blank(),
panel.background = element_rect(fill = "white"),
axis.ticks = element_blank()) +
labs(x="Driving feature", y = "Capturing feature")
nrow(random_results_matrix)
head(random_results_matrix)
plot(1:10)
